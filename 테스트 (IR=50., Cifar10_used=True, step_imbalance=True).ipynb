{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c84071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from CifarImbalanced import CIFAR10, CIFAR100\n",
    "from FocalLossV5 import FocalLoss\n",
    "\n",
    "from EnsembleV2 import resnext29_16_64, resnext47_16_64, resnext56_16_64\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "def acc(outputs, labels):\n",
    "    _, preds = torch.max(outputs.data, 1) # output 각 이미지마다 가장 큰 확률의 인덱스(=class 번호)를 변수 preds에 저장\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)) # 분류가 잘된 개수로 정확도 산출\n",
    "\n",
    "def train(model, trainLoader, criterion, optimizer, use_cuda=True, weights_for_classes=None):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "    runningCorrects = 0\n",
    "    runningCorrectsEnsembleUnweighted = 0.0\n",
    "\n",
    "    for inputs, labels in trainLoader:\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs, out1x1, out2x1,out3x1,out4x1,out5x1 = model(x=inputs)\n",
    "            acc0 = acc(outputs, labels)\n",
    "            acc1 = acc(out1x1, labels)\n",
    "            acc2 = acc(out2x1, labels)\n",
    "            acc3 = acc(out3x1, labels)\n",
    "            acc4 = acc(out4x1, labels)\n",
    "            acc5 = acc(out5x1, labels)\n",
    "\n",
    "            w_for_classifier_sum = acc0+acc1+acc2+acc3+acc4+acc5\n",
    "            w_for_classifier0 = acc0/w_for_classifier_sum\n",
    "            w_for_classifier1 = acc1/w_for_classifier_sum\n",
    "            w_for_classifier2 = acc2/w_for_classifier_sum\n",
    "            w_for_classifier3 = acc3/w_for_classifier_sum\n",
    "            w_for_classifier4 = acc4/w_for_classifier_sum\n",
    "            w_for_classifier5 = acc5/w_for_classifier_sum\n",
    "\n",
    "            w_for_instances = torch.zeros(outputs.size(0), 1)\n",
    "            if use_cuda:\n",
    "                w_for_instances = w_for_instances.cuda()\n",
    "            #    weights_for_classes = weights_for_classes.cuda()\n",
    "\n",
    "            weights_for_classes = None\n",
    "            \n",
    "            loss1, w_for_instances = criterion(out1x1, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "            loss2, w_for_instances = criterion(out2x1, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "            loss3, w_for_instances = criterion(out3x1, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "            loss4, w_for_instances = criterion(out4x1, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "            loss5, w_for_instances = criterion(out5x1, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "\n",
    "            loss0, w_for_instances = criterion(outputs, labels.long(), w_for_instances, weight=weights_for_classes)\n",
    "            \n",
    "            #loss = loss0+0.3*loss1+0.3*loss2+0.3*loss3+0.3*loss4+0.3*loss5\n",
    "            loss = loss0+loss1+loss2+loss3+loss4+loss5\n",
    "\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, preds1 = torch.max(out1x1, 1)\n",
    "            _, preds2 = torch.max(out2x1, 1)\n",
    "            _, preds3 = torch.max(out3x1, 1)\n",
    "            _, preds4 = torch.max(out4x1, 1)\n",
    "            _, preds5 = torch.max(out5x1, 1)\n",
    "            \n",
    "            outputsEnsemble_unweighted = torch.zeros(outputs.size())\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                outputsEnsemble_unweighted[i, preds[i]] = outputsEnsemble_unweighted[i, preds[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds1[i]] = outputsEnsemble_unweighted[i, preds1[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds2[i]] = outputsEnsemble_unweighted[i, preds2[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds3[i]] = outputsEnsemble_unweighted[i, preds3[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds4[i]] = outputsEnsemble_unweighted[i, preds4[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds5[i]] = outputsEnsemble_unweighted[i, preds5[i]] + 1\n",
    "            \n",
    "            _, predsEnsembleUnweighted = torch.max(outputsEnsemble_unweighted, 1)\n",
    "            \n",
    "            if use_cuda:\n",
    "                runningCorrectsEnsembleUnweighted = runningCorrectsEnsembleUnweighted+ torch.sum(predsEnsembleUnweighted.cuda()==labels.data).cpu()\n",
    "            else:\n",
    "                runningCorrectsEnsembleUnweighted = runningCorrectsEnsembleUnweighted+ torch.sum(predsEnsembleUnweighted==labels.data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "        runningLoss += loss.item() * inputs.size(0)\n",
    "        runningCorrects = runningCorrects + torch.sum(preds == labels.data)\n",
    "\n",
    "        \n",
    "        overallLoss = [w_for_classifier0,w_for_classifier1,w_for_classifier2,w_for_classifier3,w_for_classifier4,w_for_classifier5]\n",
    "        if use_cuda:\n",
    "            model.module.setWeights(overallLoss)\n",
    "        else:\n",
    "            model.setWeights(overallLoss)\n",
    "    \n",
    "    epochLoss = runningLoss / len(trainLoader.dataset)\n",
    "    epochAcc = runningCorrects.double() / len(trainLoader.dataset)\n",
    "    epochAccEnsembleUnweighted = runningCorrectsEnsembleUnweighted.double() / len(trainLoader.dataset)\n",
    "    print('Train Loss: {:.4f} Acc:{:.4f} EnsembleAcc:{:.4f}'.format(epochLoss, epochAcc, epochAccEnsembleUnweighted))\n",
    "    return (epochLoss, epochAcc, epochAccEnsembleUnweighted)\n",
    "\n",
    "def validate(model, testLoader, criterion, optimizer, use_cuda=True):\n",
    "    #print('test on validation')\n",
    "    model.eval()\n",
    "    runningLoss = 0.0\n",
    "    runningCorrects = 0.0\n",
    "   \n",
    "    runningCorrectsEnsemble=0.0\n",
    "    runningCorrectsEnsembleUnweighted = 0.0\n",
    "    runningCorrectsEnsemble_plus = 0.0\n",
    "    runningCorrectsEnsembleUnweighted_plus = 0.0\n",
    "    if use_cuda:\n",
    "        w = model.module.getWeights()\n",
    "    else:\n",
    "        w = model.getWeights()\n",
    "    #w = [1,1,1,1,1,1]\n",
    "    for inputs, labels in testLoader:\n",
    "        if use_cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            optimizer.zero_grad()\n",
    "            outputs,out1x1,out2x1,out3x1,out4x1,out5x1 = model(x=inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, preds1 = torch.max(out1x1, 1)\n",
    "            _, preds2 = torch.max(out2x1, 1)\n",
    "            _, preds3 = torch.max(out3x1, 1)\n",
    "            _, preds4 = torch.max(out4x1, 1)\n",
    "            _, preds5 = torch.max(out5x1, 1)\n",
    "            \n",
    "            outputsEnsemble = torch.zeros(outputs.size())\n",
    "            outputsEnsemble_unweighted = torch.zeros(outputs.size())\n",
    "\n",
    "            outputEnsemble_plus = outputs*w[0]+out1x1*w[1]+out2x1*w[2]+out3x1*w[3]+out4x1*w[4]+out5x1*w[5]\n",
    "            outputEnsemble_unweighted_plus = outputs+out1x1+out2x1+out3x1+out4x1+out5x1\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                outputsEnsemble[i, preds[i]] = outputsEnsemble[i, preds[i]] + w[0]\n",
    "                outputsEnsemble[i, preds1[i]] = outputsEnsemble[i, preds1[i]] + w[1]\n",
    "                outputsEnsemble[i, preds2[i]] = outputsEnsemble[i, preds2[i]] + w[2]\n",
    "                outputsEnsemble[i, preds3[i]] = outputsEnsemble[i, preds3[i]] + w[3]\n",
    "                outputsEnsemble[i, preds4[i]] = outputsEnsemble[i, preds4[i]] + w[4]\n",
    "                outputsEnsemble[i, preds5[i]] = outputsEnsemble[i, preds5[i]] + w[5]\n",
    "\n",
    "                outputsEnsemble_unweighted[i, preds[i]] = outputsEnsemble_unweighted[i, preds[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds1[i]] = outputsEnsemble_unweighted[i, preds1[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds2[i]] = outputsEnsemble_unweighted[i, preds2[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds3[i]] = outputsEnsemble_unweighted[i, preds3[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds4[i]] = outputsEnsemble_unweighted[i, preds4[i]] + 1\n",
    "                outputsEnsemble_unweighted[i, preds5[i]] = outputsEnsemble_unweighted[i, preds5[i]] + 1\n",
    "            \n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            _, predsEnsemble = torch.max(outputsEnsemble, 1)\n",
    "            _, predsEnsembleUnweighted = torch.max(outputsEnsemble_unweighted, 1)\n",
    "            _, predsEnsemble_plus = torch.max(outputEnsemble_plus, 1)\n",
    "            _, predsEnsembleUnweighted_plus = torch.max(outputEnsemble_unweighted_plus, 1)\n",
    "            \n",
    "            if use_cuda:\n",
    "                runningCorrects = runningCorrects + torch.sum(preds==labels.data).cpu()\n",
    "                runningCorrectsEnsemble = runningCorrectsEnsemble + torch.sum(predsEnsemble.cuda()==labels.data).cpu()\n",
    "                runningCorrectsEnsembleUnweighted = runningCorrectsEnsembleUnweighted+ torch.sum(predsEnsembleUnweighted.cuda()==labels.data).cpu()\n",
    "                runningCorrectsEnsemble_plus = runningCorrectsEnsemble_plus + torch.sum(predsEnsemble_plus.cuda()==labels.data).cpu()\n",
    "                runningCorrectsEnsembleUnweighted_plus = runningCorrectsEnsembleUnweighted_plus+ torch.sum(predsEnsembleUnweighted_plus.cuda()==labels.data).cpu()\n",
    "            else:\n",
    "                runningCorrects = runningCorrects + torch.sum(preds==labels.data)\n",
    "                runningCorrectsEnsemble = runningCorrectsEnsemble + torch.sum(predsEnsemble==labels.data)\n",
    "                runningCorrectsEnsembleUnweighted = runningCorrectsEnsembleUnweighted+ torch.sum(predsEnsembleUnweighted==labels.data)\n",
    "                runningCorrectsEnsemble_plus = runningCorrectsEnsemble_plus + torch.sum(predsEnsemble_plus==labels.data)\n",
    "                runningCorrectsEnsembleUnweighted_plus = runningCorrectsEnsembleUnweighted_plus+ torch.sum(predsEnsembleUnweighted_plus==labels.data)\n",
    "            \n",
    "    \n",
    "    epochAcc = runningCorrects.double() / len(testLoader.dataset)\n",
    "    epochAccEnsemble = runningCorrectsEnsemble.double() / len(testLoader.dataset)\n",
    "    epochAccEnsembleUnweighted = runningCorrectsEnsembleUnweighted.double() / len(testLoader.dataset)\n",
    "    epochAccEnsemble_plus = runningCorrectsEnsemble_plus.double() / len(testLoader.dataset)\n",
    "    epochAccEnsembleUnweighted_plus = runningCorrectsEnsembleUnweighted_plus.double() / len(testLoader.dataset)\n",
    "    \n",
    "    print('Acc:{:.4f}   EnsembleAcc:{:.4f}   EnsembleUnweightedAcc:{:.4f}   Ensemble_plus:{:.4f}  Ensemble_unweighted:{:.4f}'.format(epochAcc, epochAccEnsemble, epochAccEnsembleUnweighted, epochAccEnsemble_plus, epochAccEnsembleUnweighted_plus))\n",
    "    \n",
    "    return ( epochAcc, epochAccEnsembleUnweighted )\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', acc=100., epoch=1):\n",
    "    if os.path.exists(checkpoint)==False:\n",
    "        os.makedirs(checkpoint)\n",
    "\n",
    "    filename = \"Epoch_\"+str(epoch)+\"_\"+str(acc)+\"_checkpoint.pth.tar\"\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, lr, epoch, schedule):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 following schedule\"\"\"\n",
    "    if epoch in schedule:\n",
    "        lr *= 0.1\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr\n",
    "\n",
    "def get_checkpoint(epoch, checkpoint='checkpoint'):\n",
    "    if os.path.exists(checkpoint)==False:\n",
    "        os.makedirs(checkpoint)\n",
    "    \n",
    "    filename = \"Epoch_\"+str(epoch)+\"_checkpoint.pth.tar\"\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    return filepath\n",
    "\n",
    "def MyEnsemble(IR=50., Cifar10_used=True, step_imbalance=True, root=\"./Result\", fine_tunning = 0):\n",
    "    if Cifar10_used:\n",
    "        num_class = 10\n",
    "    else:\n",
    "        num_class = 100\n",
    "    \n",
    "    learningRate = 0.05\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    batchSize = 100 #원래는 100인데 수정\n",
    "\n",
    "    start_epoch = 0\n",
    "    epochs = 100 #원래는 100인데 수정\n",
    "    schedule = [30, 60, 90, 100]\n",
    "    gamma = 2.0\n",
    "    if step_imbalance:\n",
    "        model_save_path = os.path.join(root, \"step_imbalance\", \"cifar\"+str(num_class), \"IR=\"+str(IR), 'MyEnsemble')\n",
    "    else:\n",
    "        model_save_path = os.path.join(root, 'long_tail', \"cifar\"+str(num_class), \"IR=\"+str(IR), str(gamma), 'MyEnsemble')\n",
    "    \n",
    "    best_prec1 = 0\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    # create model\n",
    "    model = resnext47_16_64(num_classes=num_class)\n",
    "    criterion = FocalLoss()\n",
    "    \n",
    "    if use_cuda:\n",
    "        #model.cuda()\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningRate,\n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    transformTrain = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    transformTest = transforms.Compose([\n",
    "            transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "    ])\n",
    "\n",
    "    if Cifar10_used:\n",
    "        trainSet = CIFAR10(root='./data', train=True, download=True, transform=transformTrain, step_imbalance=step_imbalance, IR=IR)\n",
    "        trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize,  shuffle=True, num_workers=4)\n",
    "        testSet = CIFAR10(root='./data', train=False, download=True, transform=transformTest)\n",
    "        testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "        weights_for_classes = trainSet.weight_for_classes\n",
    "    else:\n",
    "        trainSet = CIFAR100(root='./data', train=True, download=True, transform=transformTrain, step_imbalance=step_imbalance, IR=IR)\n",
    "        trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=batchSize,  shuffle=True, num_workers=4)\n",
    "        testSet = CIFAR100(root='./data', train=False, download=True, transform=transformTest)\n",
    "        testLoader = torch.utils.data.DataLoader(testSet, batch_size=batchSize, shuffle=True, num_workers=4)\n",
    "        weights_for_classes = trainSet.weight_for_classes\n",
    "    if fine_tunning>0:\n",
    "        resume = get_checkpoint(fine_tunning, model_save_path)\n",
    "        if os.path.isfile(resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(resume, checkpoint['epoch']))\n",
    "            checkpoint = os.path.dirname(resume)\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "    \n",
    "    singleTrainAcc = []\n",
    "    singleTestAcc = []\n",
    "    ensembleTrainAcc = []\n",
    "    ensembleTestAcc = []\n",
    "    #training & evaluation\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        learningRate = adjust_learning_rate(optimizer, learningRate, epoch, schedule)\n",
    "        print('\\nEpoch: [%d | %d] LR: %f' % (epoch + 1, epochs, learningRate))\n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss, train_acc, ensembleAcc = train(model, trainLoader, criterion, optimizer, use_cuda=use_cuda, weights_for_classes=weights_for_classes)\n",
    "        singleAcc, prec1 = validate(model, testLoader, criterion, optimizer, use_cuda=use_cuda)\n",
    "\n",
    "        singleTrainAcc.append(train_acc.cpu().numpy())\n",
    "        singleTestAcc.append(singleAcc.cpu().numpy())\n",
    "        ensembleTrainAcc.append(ensembleAcc.cpu().numpy())\n",
    "        ensembleTestAcc.append(prec1.cpu().numpy())\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        if (epoch % 5)==0:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': prec1,\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, is_best, checkpoint=model_save_path, acc=prec1.cpu().numpy(), epoch=epoch+1)\n",
    "\n",
    "    print('Best accuracy:')\n",
    "    print(best_prec1)\n",
    "    print(singleTrainAcc)\n",
    "    print(singleTestAcc)\n",
    "    print(ensembleTrainAcc)\n",
    "    print(ensembleTestAcc)\n",
    "\n",
    "    return best_prec1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1557a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "1___25505\n",
      "[5000, 4456, 3912, 3367, 2823, 2278, 1734, 1189, 645, 101]\n",
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: [1 | 100] LR: 0.050000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qmffp\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:780: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
      "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.5045 Acc:0.3226 EnsembleAcc:0.3491\n",
      "Acc:0.2867   EnsembleAcc:0.2621   EnsembleUnweightedAcc:0.2640   Ensemble_plus:0.2658  Ensemble_unweighted:0.2690\n",
      "\n",
      "Epoch: [2 | 100] LR: 0.050000\n",
      "Train Loss: 7.0892 Acc:0.4293 EnsembleAcc:0.4465\n",
      "Acc:0.3039   EnsembleAcc:0.3192   EnsembleUnweightedAcc:0.3241   Ensemble_plus:0.3354  Ensemble_unweighted:0.3320\n",
      "\n",
      "Epoch: [3 | 100] LR: 0.050000\n",
      "Train Loss: 6.4757 Acc:0.4838 EnsembleAcc:0.4902\n",
      "Acc:0.3695   EnsembleAcc:0.3293   EnsembleUnweightedAcc:0.3545   Ensemble_plus:0.3346  Ensemble_unweighted:0.3775\n",
      "\n",
      "Epoch: [4 | 100] LR: 0.050000\n",
      "Train Loss: 6.0941 Acc:0.4963 EnsembleAcc:0.5192\n",
      "Acc:0.4107   EnsembleAcc:0.3939   EnsembleUnweightedAcc:0.3792   Ensemble_plus:0.3889  Ensemble_unweighted:0.3889\n",
      "\n",
      "Epoch: [5 | 100] LR: 0.050000\n",
      "Train Loss: 5.5529 Acc:0.5537 EnsembleAcc:0.5585\n",
      "Acc:0.3448   EnsembleAcc:0.3643   EnsembleUnweightedAcc:0.3571   Ensemble_plus:0.3685  Ensemble_unweighted:0.3691\n",
      "\n",
      "Epoch: [6 | 100] LR: 0.050000\n",
      "Train Loss: 5.1406 Acc:0.5919 EnsembleAcc:0.5917\n",
      "Acc:0.3538   EnsembleAcc:0.3958   EnsembleUnweightedAcc:0.3958   Ensemble_plus:0.4149  Ensemble_unweighted:0.4149\n",
      "\n",
      "Epoch: [7 | 100] LR: 0.050000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15420/3889879414.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mMyEnsemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15420/3347159119.py\u001b[0m in \u001b[0;36mMyEnsemble\u001b[1;34m(IR, Cifar10_used, step_imbalance, root, fine_tunning)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m         \u001b[1;31m# train for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensembleAcc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights_for_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights_for_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m         \u001b[0msingleAcc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestLoader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15420/3347159119.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, trainLoader, criterion, optimizer, use_cuda, weights_for_classes)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout1x1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout2x1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout3x1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout4x1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout5x1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0macc0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0macc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout1x1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\EnsembleV2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, targets, lam)\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[0maux_result3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maux_layer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_input4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[0maux_result4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maux_layer4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux_input4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0maux_result5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maux_layer5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\EnsembleV2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    237\u001b[0m                     \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m                     \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         '''\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\EnsembleV2.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mbottleneck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mbottleneck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0mbottleneck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_expand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2419\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2421\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2422\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2423\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MyEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db5fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
